\chapter{Conclusões e Trabalhos Futuros}\label{chap7}


Experimentos científicos computacionalmente intensivos geralmente produzem um grande volume de dados e apresentam  uma longa duração, na qual várias execuções, utilizando diferentes parâmetros e dados de entrada, são necessárias para obter resultados. Esses experimentos são comumente modelados como \textit{workflows} científicos, que são compostos por uma cadeia de atividades que representam diferentes conjuntos de tarefas. Cada tarefa é associada a uma execução de uma atividade para uma porção especificada dos dados ou para um conjunto de valores de parâmetros. Essas tarefas são executadas em paralelo em ambientes HPC para produzir resultados a um tempo aceitável.

% Data- and compute-intensive scientific experiments usually produce a huge volume of data and present a long duration where several executions, using different parameters and input data, are necessary to draw conclusions. These experiments are commonly modeled as scientific workflows, which are composed by a chain of activities and each activity can be further decomposed in a set of tasks. Each task is associated with the execution of an activity for a specific portion of data or set of parameter values. These tasks have to be executed in parallel in HPC environments to produce results in a feasible time with good performance. 

No entanto, não é trivial gerenciar execuções paralelas de WfCs, particularmente na nuvem. Uma questão importante a ser considerada na execução em ambientes de nuvem é como escalonar as várias tarefas a um conjunto de MVs heterogêneas. O escalonamento de tarefas é um problema NP-Difícil bem conhecido, mesmo na sua forma simples. Além disso, para escalonar as tarefas para MVs várias características devem ser levadas em consideração, tais como a capacidade de processamento, capacidade de armazenamento e o impacto das transferências de dados no tempo total de execução. Este trabalho parte da ideia de que o problema de escalonamento de tarefas e o problema de alocação de dados não são independentes e, portanto, devem ser analisados de forma conjunta pela abordagem de escalonamento. 

% However, it is far from trivial to manage the parallel executions of data- and compute-intensive scientific workflows, particularly in clouds. One important issue to consider when executing workflows in parallel in clouds is how to schedule the multiple tasks to a set of heterogeneous VMs. Task scheduling is a well-known NP-complete problem even in its simplest form. But to schedule the tasks to VMs we have to consider several requirements such as the processing capacity of the VM, its storage capacity and the impact of data transfer. In this article we claim that data distribution and task distribution are not independent problems and have to be analyzed together by the scheduling approach. In previous work \cite{Oliveira2012} we have addressed workflow execution in clouds using a greedy scheduling algorithm but it does not consider data placement in the scheduling algorithm, which may imply in severe overheads. Thus, to increase the uptake of the cloud paradigm for executing scientific workflows that demand HPC capabilities, new scheduling solutions have to be developed.  

Neste trabalho, um novo modelo de representação de \textit{workflow} foi proposto, junto a uma formulação matemática do problema de escalonamento de dados e distribuição de tarefas e um algoritmo de escalonamento evolutivo hibrido chamado AEH-ETAA que considera a heterogeneidade das MVs no ambiente de nuvem (diferentes larguras de banda, capacidade de processamento e armazenamento), a distribuição dos dados e as restrições, todos juntos na mesma solução, ou seja, as tarefas e os arquivos são escalonados juntos pelo SGWfC.

% In this article,  we propose a new  model  for representing workflows, a mathematical formulation of The Task Scheduling and Data Assignment Problem and a scheduling algorithm based on Hybrid Evolutionary Algorithm (HEA) named HEA-TaSDAP that takes into account the variety and heterogeneity of VMs in cloud virtual cluster (\textit{e.g.} different bandwidths, transfer rates, and processing capacities), the data distribution and data constraints all together within the same solution, \textit{i.e.} tasks and data files are scheduled together by the SWfMS.

O AEH-ETAA foi avaliado utilizando \textit{workflows} sintéticos e reais utilizando o SGWfCs SciCumulus. A avaliação de performance do AEH-ETAA em comparação com a solução exata, mostrou que, para todas as instâncias, o AEH-ETAA obtém boas soluções com pequenas diferenças percentuais, na média $2,6\%$. Além disso, o algoritmo  leva um tempo significativamente menor quando comparado à formulação matemática solucionada com o CPLEX, em média $1,5$s contra $1942,7$s, respectivamente. Na execução real, foi utilizado o SciPhy como estudo de caso para a comparação do AEH-ETAA com o algoritmo guloso do SciCumulus Greedy-SC, MinMin e HEFT. O tempo de execução do SciPhy quando executado com o plano de escalonamento dado pelo AEH-ETAA foi em torno de $27,4\%$ menor que o dado pelo algoritmo guloso, $11,7\%$ menor que o MinMin e $8,1\%$ menor que o HEFT. 

Como trabalhos futuros, a abordagem proposta será incrementado com técnicas de tolerância a falhas que  realizarão \textit{backups} das tarefas, e possibilitarão a recuperação parcial, ou total, dos processos caso haja interrupções devido a ocorrência de falhas no ambiente. Além disso, também serão adotadas técnicas de redimensionamento do ambiente que serão capazes de alocar e desalocar as MVs durante a execução do \textit{workflow}. As técnicas de redimensionamento são importantes nos ambientes de nuvens, pois possibilitam diminuir o custo financeiro associado ao ambiente. Outro trabalho interessante é a inclusão de outros objetivos (abordagem multiobjetivo) no modelo proposto, como minimizar os custos financeiros e o \textit{makespan}, respeitando o tempo limite de execução definido pelo usuário e um valor máximo de orçamento. 

% We have evaluated HEA-TaSDAP using synthetic and real workflows in the cloud using SciCumulus. The performance evaluation of the HEA-TasDAP using synthetic workflows in comparison with the exact solution showed that for all instances HEA-TaSDAP obtains good solutions with small gaps, in average $2.6\%$. Moreover, it takes significantly less time when compared with the mathematical formulation when solved with the CPLEX, in average $1.5$s against $1942.7$s, respectively. In the real execution, we used SciPhy as a case study and compared HEA-TaDASP with the greedy scheduling of SciCumulus, MinMin-TSH and HEFT. The execution time of SciPhy when using the scheduling plan provided by HEA-TaSDAP was about 27.4\% smaller than the one using the greedy algorithm, 11.7\% smaller than MinMin-TSH and 8.1\% smaller than using HEFT. As future work, we plan to use the proposed approach in conjunction with a fault-tolerance and a dimensioning mechanism within the scheduler to distribute backups of tasks and then execute the workflow with more reliability. Another interesting work could involve considering  other objectives in our model like  minimization of  financial costs and power consumption, respecting tasks deadlines. Finally, we also intend to tackle the data replication problem in our models, as previous commented in Section \ref{sec:problemDef}.



